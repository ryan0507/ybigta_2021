{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제1: tensorflow를 이용한 NN 밑바닥부터 구현\n",
    "input feature가 100개이고,  \n",
    "hidden layer가 2개이고 neuron이 각각 50,10개이고,  \n",
    "output이 5개인 NN를 구현해 보자  \n",
    "* hidden layer는 relu를 activation function으로, output layer는 softmax를 activation function으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 100\n",
    "n_h1 = 50\n",
    "n_h2 = 10\n",
    "n_y = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0885577   1.0672758   0.29632506 ...  0.9496118  -0.88863903\n",
      "  -0.85583717]\n",
      " [ 0.9394478   0.12897761  0.52227557 ...  1.8456537   1.4178325\n",
      "   0.5443067 ]\n",
      " [ 2.245257   -0.06821159  0.5527033  ... -2.2933981   0.41008732\n",
      "  -0.45321187]\n",
      " ...\n",
      " [-1.0562221   1.8306357  -1.9416912  ... -1.4566288   0.23735301\n",
      "   2.3493292 ]\n",
      " [-0.6376614   0.93972445  1.3685744  ... -1.0588197   0.8072748\n",
      "  -1.8455015 ]\n",
      " [-1.4023174   1.5464463   0.4653848  ... -1.1526694  -0.79176384\n",
      "   0.14664319]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Simulate train set\n",
    "m = 500\n",
    "\n",
    "x_train=np.random.randn(m,n_x).astype(np.float32)\n",
    "y_train=np.zeros((m,n_y)).astype(np.float32)\n",
    "y_train[np.arange(m),np.random.randint(n_y,size=m)]=1\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialization of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=tf.Variable(1e-3*np.random.randn(n_x,n_h1).astype(np.float32),name=\"w1\")\n",
    "## 코드를 작성해 보세요 ##\n",
    "w2=tf.Variable(1e-3*np.random.randn(n_h1,n_h2).astype(np.float32),name=\"w2\")\n",
    "w3= tf.Variable(1e-3*np.random.randn(n_h2,n_y).astype(np.float32),name=\"w3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* forward propagation을 통해 prediction 값을 구하고, loss를 구하는 function을 만들어 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    z1=tf.matmul(x,w1)\n",
    "    a1=tf.nn.relu(z1)\n",
    "    ## 코드를 작성해 보세요 ##\n",
    "    z2=tf.matmul(a1,w2)\n",
    "    a2=tf.nn.relu(z2)\n",
    "    z3=tf.matmul(a2,w3)\n",
    "    predictions = tf.nn.softmax(z3)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def loss_fn(predictions, y):\n",
    "    loss= -tf.reduce_sum(y*tf.math.log(predictions))\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* backpropagation & update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-2\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = forward(x)\n",
    "        loss = loss_fn(predictions, y)\n",
    "    ## 코드를 작성해 보세요 ## (hint: tape.gradient를 구글링 해보세요)\n",
    "    gradient = tape.gradient(loss, [w1, w2])\n",
    "    # optimizer와 위에서 구한 경사도를 이용해 가중치들을 업데이트 합니다.\n",
    "    optimizer.apply_gradients(zip(gradient, [w1, w2]))\n",
    "    return loss, w1, w2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 간단하게 train loop를 작성해 loss가 줄어나가는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804.7185, 804.71576, 804.69824, 804.6642, 804.6095, 804.53174, 804.4282, 804.29553, 804.1332, 803.9386]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for step in range(10): \n",
    "    loss, w1, w2 = train_step(x_train, y_train)\n",
    "    loss_list.append(loss.numpy())\n",
    "    \n",
    "print(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제2: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
    "\n",
    "\n",
    "## Loading MNIST training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Loading the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scaling(image data는 min-max scaling 주로 사용)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
    "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1].reshape((28 , 28))).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Labels\n",
    "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
    "마찬가지로, 60000개의 label이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label for above data\n",
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]\n",
    "\n",
    "loss_list = [\"sparse_categorical_crossentropy\",\n",
    "             \"categorical_crossentropy\", \n",
    "             \"binary_crossentropy\"]\n",
    "\n",
    "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]\n",
    "\n",
    "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
    "                    tf.keras.initializers.RandomUniform(), \n",
    "                    tf.keras.initializers.he_normal(), \n",
    "                    tf.keras.initializers.he_uniform(), \n",
    "                    tf.keras.initializers.GlorotUniform(),\n",
    "                    tf.keras.initializers.GlorotNormal()]\n",
    "\n",
    "# dropout\n",
    "dropout_rate = 0.3\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation = \"sigmoid\"),\n",
    "    tf.keras.layers.Dense(2, activation = \"sigmoid\"),\n",
    "    tf.keras.layers.Dropout(dropout_rate)\n",
    "])\n",
    "\n",
    "\n",
    "# regularizer\n",
    "regularizer = tf.keras.regularizers.l1(1e-3)\n",
    "regularizer = tf.keras.regularizers.l2(1e-3)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
    "                          activity_regularizer=regularizer)\n",
    "])\n",
    "\n",
    "# weight initialization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
    "                          kernel_initializer=initializer_list[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Own Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 자유롭게 Model을 만들고 compile 해봅시다 ####\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(units = 256,  input_dim = 28 * 28 , activation = 'relu', name= 'D1'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내가 만든 모델을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model을 자유롭게 train 해봅시다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95%이상의 성능을 가진 모델을 만들면 완성!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ybigta",
   "language": "python",
   "name": "ybigta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
